{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[54 循环神经网络 RNN](https://www.bilibili.com/video/BV1D64y1z7CA?spm_id_from=333.999.0.0)\n",
    "- <img src=\"picture/屏幕截图 2022-05-31 191341.png\">\n",
    "- 新概念h：隐变量，这个变量是真实存在的，但无法被感知到的变量\n",
    "- 输出$o_t只能由隐变量h_t和x_{t-1}共同进行输出，不能由x_t直接输出$\n",
    "- $h_t = \\phi(W_{hh}h_{t-1}+W_{}{hx}X_{t-1}+b_h)$\n",
    "- $o_t = \\phi(W_{oh}+b_o)这里视频有误是W_{oh}$\n",
    "- <img src=\"picture/屏幕截图 2022-05-31 191542.png\">\n",
    "- 输出$o_t是作为当前时刻的预测值，预测x_t的值$\n",
    "- <img src=\"picture/屏幕截图 2022-05-31 193028.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 困惑度 perplexity\n",
    "- 衡量一个模型的好坏可以用平均交叉熵来衡量\n",
    "- $$\\pi = \\frac{1}{n} \\sum_{t=1}^n -\\log P(x_t \\mid x_{t-1}, \\ldots, x_1)$$\n",
    "- p是语言模型的预测概率，$x_t$是真实词\n",
    "- 历史原因NLP使用$exp(\\pi)$来衡量（能够扩大相应的值，直接使用会太小）\n",
    "- 1表示完美。无穷大是最差情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <img src=\"picture/屏幕截图 2022-05-31 230201.png\">\n",
    "- 主要应用\n",
    "- <img src=\"picture/屏幕截图 2022-05-31 231212.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[55 循环神经网络 RNN 的实现](https://www.bilibili.com/video/BV1kq4y1H7sw/?spm_id_from=333.788.recommend_more_video.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开炼！\n",
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "# vocab\n",
    "batch_size,num_steps = 32,35\n",
    "train_iter,vocab = d2l.load_data_time_machine(batch_size,num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 35])\n",
      "tensor([15,  9,  5,  6,  2,  1, 21, 19,  1,  9,  1, 18,  1, 17,  2, 12, 12,  8,\n",
      "         5,  3,  9,  2,  1,  3,  5, 13,  2,  1,  3, 10,  4, 22,  2, 12, 12])\n",
      "torch.Size([32, 35])\n",
      "tensor([ 9,  5,  6,  2,  1, 21, 19,  1,  9,  1, 18,  1, 17,  2, 12, 12,  8,  5,\n",
      "         3,  9,  2,  1,  3,  5, 13,  2,  1,  3, 10,  4, 22,  2, 12, 12,  2])\n"
     ]
    }
   ],
   "source": [
    "for x in train_iter:\n",
    "    print(x[0].shape)\n",
    "    print(x[0][0])\n",
    "    print(x[1].shape)\n",
    "    print(x[1][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 29927),\n",
       " ('e', 17838),\n",
       " ('t', 13515),\n",
       " ('a', 11704),\n",
       " ('i', 10138),\n",
       " ('n', 9917),\n",
       " ('o', 9758),\n",
       " ('s', 8486),\n",
       " ('h', 8257),\n",
       " ('r', 7674),\n",
       " ('d', 6337),\n",
       " ('l', 6146),\n",
       " ('m', 4043),\n",
       " ('u', 3805),\n",
       " ('c', 3424),\n",
       " ('f', 3354),\n",
       " ('w', 3225),\n",
       " ('g', 3075),\n",
       " ('y', 2679),\n",
       " ('p', 2427),\n",
       " ('b', 1897),\n",
       " ('v', 1295),\n",
       " ('k', 1087),\n",
       " ('x', 236),\n",
       " ('z', 144),\n",
       " ('j', 97),\n",
       " ('q', 95)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.token_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 独热编码\n",
    "F.one_hot(torch.tensor([0,2,12]),len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 小批量数据的形状是（批量大小,时间步数）\n",
    "# rnn的时间步长可以理解为tau，也是错位的序列\n",
    "# 由于文本是连续的，时间步长在文本上就表现为单词的连续，例如时间步数为5，就表示5元组成一个序列\n",
    "# 批量大小指的是多少个序列组成一组\n",
    "X = torch.arange(10).reshape(2,5)\n",
    "F.one_hot(X.T,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化参数模型\n",
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device) * 0.01\n",
    "\n",
    "    # 隐藏层参数\n",
    "    W_xh = normal((num_inputs, num_hiddens))\n",
    "    W_hh = normal((num_hiddens, num_hiddens))\n",
    "    b_h = torch.zeros(num_hiddens, device=device)\n",
    "    # 输出层参数\n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    # 附加梯度\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ff4e656d48086ea967ec377ef26a3ddd3b4429bca6c045e20f6b3e90b5d3e65"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
